{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from thefuzz import fuzz #new fuzzywuzzy project https://github.com/seatgeek/thefuzz\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Library\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(value):\n",
    "    if type(value)==str:\n",
    "        return (value.upper() == 'NAN')\n",
    "    else:\n",
    "        return np.isnan(value)\n",
    "    \n",
    "def areEquivalentValues(val1, val2, equivalences):\n",
    "    return (val1==val2 or (val1,val2) in equivalences) or ((val2,val1) in equivalences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compatibleRanges(row1, row2, options, verbose=False):\n",
    "    compatible = True #need to be compatible on all available fields (can be changed for 'or')\n",
    "    allowNa = options['na.action'] == 'all'\n",
    "    \n",
    "    #for debugging\n",
    "    val1 = val2 = 'NAN'\n",
    "    \n",
    "    for field in options['fields'].split(' '):        \n",
    "        if field not in row1 or field not in row2:\n",
    "            continue\n",
    "        \n",
    "        if isNaN(row1[field]) or isNaN(row2[field]):\n",
    "            compatible &= allowNa\n",
    "        else:\n",
    "            compatible &= abs(int(row1[field]) - int(row2[field])) <= int(options['parameter'])\n",
    "            val1 = int(row1[field])\n",
    "            val2 = int(row2[field])\n",
    "            \n",
    "    #for debugging\n",
    "    if verbose: \n",
    "        print(f\"\\tval1:{val1}, val2:{val2}, allowNa: {allowNa}, range:{int(options['parameter'])}\")\n",
    "    \n",
    "    return compatible\n",
    "\n",
    "def compatibleCategory(row1, row2, options, verbose=False):\n",
    "    compatible = True #need to be compatible on all available fields (can be changed for 'or')\n",
    "    allowNa = options['na.action'].upper() == 'ALL'\n",
    "    equivalences = None\n",
    "    \n",
    "    #for debugging\n",
    "    val1 = val2 = 'NAN'\n",
    "    \n",
    "    if not isNaN(options['parameter']):\n",
    "        equivalencesDF = pd.read_csv(f\"{configPath}/{options['parameter']}\")\n",
    "        equivalences = list(equivalencesDF.itertuples(index=False, name=None))\n",
    "        # WARNING, there may be a better way to do this other than creating tuples but we should have a scheme\n",
    "        # to follow, in order to grab the columns without having to specify their names\n",
    "    \n",
    "    for field in options['fields'].split(' '):\n",
    "        if field not in row1 or field not in row2:\n",
    "            continue\n",
    "        \n",
    "        if isNaN(row1[field]) or isNaN(row2[field]):\n",
    "            compatible &= allowNa\n",
    "        elif equivalences:\n",
    "            compatible &= areEquivalentValues(row1[field], row2[field], equivalences)\n",
    "            val1 = row1[field]\n",
    "            val2 = row2[field]\n",
    "    \n",
    "    #for debugging\n",
    "    if verbose: \n",
    "        print(f\"\\tval1:{val1}, val2:{val2}, allowNa: {allowNa}\")\n",
    "    \n",
    "    return compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areCompatibles(row1, row2, verbose=False):\n",
    "    compatible = True\n",
    "        \n",
    "    for variable, options in comparisonSettings.items():    \n",
    "        if options['consider'].lower() == 'yes':\n",
    "            if verbose:\n",
    "                print(f\"{variable} compatible?\")\n",
    "            varCompatible = True\n",
    "\n",
    "            if options['type'] == 'range':\n",
    "                varCompatible = compatibleRanges(row1, row2, options, verbose)\n",
    "            elif options['type'] == 'categorical':\n",
    "                varCompatible = compatibleCategory(row1, row2, options, verbose)\n",
    "\n",
    "            compatible &= varCompatible\n",
    "            if verbose:\n",
    "                print(f\"\\tresult: {varCompatible}\")\n",
    "    if verbose:\n",
    "        print(f\"Candidates? {compatible} \\n\\n\")\n",
    "    return compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areCandidates(row1, row2, verbose=False):\n",
    "    candidates = True\n",
    "\n",
    "    for scheme, key1, key2, threshold in schemesConfig.itertuples(index=False):\n",
    "        #check for valid scheme and keys\n",
    "        if scheme not in schemes:\n",
    "            if verbose:\n",
    "                print(f\"scheme not used: {scheme}\")\n",
    "            continue\n",
    "        if verbose:\n",
    "            print(f\"scheme {scheme}\")\n",
    "        if key1 not in base1.columns:\n",
    "            print(f\"invalid key on database 1 {key1}, skipping\")\n",
    "            continue\n",
    "        if key2 not in base2.columns:\n",
    "            print(f\"invalid key on database 2 {key2}, skipping\")\n",
    "            continue\n",
    "\n",
    "        value1 = row1[key1]\n",
    "        value2 = row2[key2]\n",
    "        \n",
    "        information = {}\n",
    "        \n",
    "        for algorithmName, algorithm in comparisonAlgorithms.items():\n",
    "            result = algorithm(value1, value2)\n",
    "            candidates &= (result >= threshold)\n",
    "\n",
    "            information[f\"{algorithmName}_{scheme}\"] = result\n",
    "    return candidates, pd.Series(information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config files\n",
    "configPath = os.path.join(os.getcwd(), 'config')\n",
    "dictionariesPath = os.path.join(os.getcwd(), 'dicts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "inputPath = os.path.join(os.getcwd(), 'example/instances')\n",
    "\n",
    "base1 = pd.read_csv(f\"{inputPath}/inst1/base_inst1.csv\")\n",
    "base2 = pd.read_csv(f\"{inputPath}/inst2/base_inst2.csv\")\n",
    "\n",
    "#output\n",
    "outputPath = os.path.join(inputPath, 'matches')\n",
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)\n",
    "    \n",
    "outputFileName = 'candidateList'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>parameter</th>\n",
       "      <th>consider</th>\n",
       "      <th>na.action</th>\n",
       "      <th>fields</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case.ID</th>\n",
       "      <td>Case.ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Case.ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cod</th>\n",
       "      <td>cod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nationality</th>\n",
       "      <td>categorical</td>\n",
       "      <td>natEquivalences.csv</td>\n",
       "      <td>yes</td>\n",
       "      <td>all</td>\n",
       "      <td>Nat_PROC Nat_2_PROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>categorical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>all</td>\n",
       "      <td>Sex_PROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>range</td>\n",
       "      <td>6</td>\n",
       "      <td>yes</td>\n",
       "      <td>all</td>\n",
       "      <td>Age_PROC Age_2_PROC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    type            parameter consider na.action  \\\n",
       "variable                                                           \n",
       "Case.ID          Case.ID                  NaN       no       NaN   \n",
       "cod                  cod                  NaN       no       NaN   \n",
       "nationality  categorical  natEquivalences.csv      yes       all   \n",
       "sex          categorical                  NaN      yes       all   \n",
       "age                range                    6      yes       all   \n",
       "\n",
       "                          fields  \n",
       "variable                          \n",
       "Case.ID                  Case.ID  \n",
       "cod                          cod  \n",
       "nationality  Nat_PROC Nat_2_PROC  \n",
       "sex                     Sex_PROC  \n",
       "age          Age_PROC Age_2_PROC  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variableFields = pd.read_csv(f\"{configPath}/variableFields.csv\").set_index('variable')\n",
    "compatibleData = pd.read_csv(f\"{configPath}/compatible_data.csv\").set_index('variable')\n",
    "\n",
    "comparisonSettings = compatibleData.join(variableFields).to_dict(orient='index')\n",
    "\n",
    "compatibleData.join(variableFields) #just to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schemes ['A_A', 'F_F']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scheme</th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_A</td>\n",
       "      <td>Name_A</td>\n",
       "      <td>Name_A</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F_F</td>\n",
       "      <td>Father_name_A</td>\n",
       "      <td>Father_name_A</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M_M</td>\n",
       "      <td>Mother_name_A</td>\n",
       "      <td>Mother_name_A</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD_AD</td>\n",
       "      <td>Adress_A</td>\n",
       "      <td>Adress_A</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ph_Ph</td>\n",
       "      <td>Phone_1_PROC Phone_2_PROC Phone_3_PROC</td>\n",
       "      <td>Phone_1_PROC Phone_2_PROC Phone_3_PROC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scheme                                    key1  \\\n",
       "0    A_A                                  Name_A   \n",
       "1    F_F                           Father_name_A   \n",
       "2    M_M                           Mother_name_A   \n",
       "3  AD_AD                                Adress_A   \n",
       "4  Ph_Ph  Phone_1_PROC Phone_2_PROC Phone_3_PROC   \n",
       "\n",
       "                                     key2  threshold  \n",
       "0                                  Name_A        0.3  \n",
       "1                           Father_name_A        0.0  \n",
       "2                           Mother_name_A        0.0  \n",
       "3                                Adress_A        0.0  \n",
       "4  Phone_1_PROC Phone_2_PROC Phone_3_PROC        0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemes = pd.read_csv(f\"{configPath}/select_schemes.csv\", names=['schemes'])['schemes'].to_list() \n",
    "print(f\"schemes {schemes}\")\n",
    "#TODO add option for \"fast scheme\"\n",
    "\n",
    "schemesConfig = pd.read_csv(f\"{configPath}/info_scheme.csv\")\n",
    "schemesConfig.rename(columns = {'listA.column': 'key1', 'listB.column': 'key2'}, inplace=True)\n",
    "if schemesConfig.dtypes['threshold'] == str:\n",
    "    schemesConfig.threshold = schemesConfig.threshold.str.replace(',', '.').astype(float)\n",
    "schemesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonAlgorithms = {\n",
    "    'Levenshtein': textdistance.levenshtein.normalized_similarity,\n",
    "    'DL': textdistance.damerau_levenshtein.normalized_similarity,\n",
    "    'fuzzy_ratio' : fuzz.ratio\n",
    "} #TODO add the rest/more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find compatible rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compatiblesDF = base1.apply(lambda row1: base2.apply(lambda row2: areCompatibles(row1, row2), axis=1), axis=1)\n",
    "i1, i2 = (compatiblesDF.values).nonzero()\n",
    "compatibles = list(zip(i1, i2))\n",
    "\n",
    "compatibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the schemes configured on the compatible pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatesList = []\n",
    "\n",
    "for i1, i2 in compatibles:\n",
    "    row1 = base1.iloc[i1]\n",
    "    row2 = base2.iloc[i2]\n",
    "    \n",
    "    candidates, information = areCandidates(row1, row2)\n",
    "\n",
    "    if candidates:\n",
    "        #rename columns as base1_ and base2_\n",
    "        row1.set_axis(['base1_'+x for x in base1.columns], inplace=True)\n",
    "        row2.set_axis(['base2_'+x for x in base2.columns], inplace=True)\n",
    "        \n",
    "        candidatesList.append(pd.concat([row1, row2, information]))\n",
    "\n",
    "candidatesDF = pd.concat(candidatesList, axis=1).T\n",
    "\n",
    "candidatesDF.to_csv(f\"{outputPath}/candidatesList.csv\", index=False)\n",
    "candidatesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exBase1 = base1.iloc[4]\n",
    "exBase2 = base2.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exBase1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exBase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "\n",
    "#Stringdist (R) Functions\n",
    "    #Levenshtein distance\n",
    "print(\"levenshtein normalized similarity\", textdistance.levenshtein.normalized_similarity('test', 'tast'))\n",
    "    \n",
    "    #D-L \n",
    "        #The restricted Damerau-Levenshtein distance is not a true distance metric because it does not \n",
    "        #satisfy the triangle inequality. This makes it a poor choice for applications that involve evaluating \n",
    "        #the similarity of more than two strings, such as clustering.\n",
    "print(\"damerau-levenshtein normalized\", textdistance.damerau_levenshtein.normalized_similarity('test', 'tast'))\n",
    "\n",
    "    #D-L-FULL ???\n",
    "    \n",
    "    #LongestCommonSubstring \n",
    "    #falta encontrar uno que haga tal cu√°l se quiere, sino se puede calcular, pero con cuidado\n",
    "ex1 = 'Jonh Smit'\n",
    "ex2 = 'John Smith'\n",
    "substr = textdistance.lcsstr(ex1, ex2)\n",
    "print(substr)\n",
    "print(\"longest common substring\", 1-len(substr)/(len(ex1)+len(ex2))) #TODO\n",
    "    \n",
    "    #GramX\n",
    "\n",
    "#FuzzyWuzzyFunctions\n",
    "    #Ratio\n",
    "print(\"fuzz.ratio('test', 'tast')\", fuzz.ratio('test', 'tast'))\n",
    "    #partial_ratio\n",
    "print(\"fuzz.partial_ratio('test', 'tast!')\", fuzz.partial_ratio('test', 'tast!'))\n",
    "print(\"fuzz.partial_ratio('test', 'test!')\", fuzz.partial_ratio('test', 'test!'))\n",
    "    #token_sort_ratio\n",
    "print(\"fuzz.ratio('fuzzy wuzzy was a bear', 'wuzzy fuzzy was a bear')\", fuzz.ratio(\"fuzzy wuzzy was a bear\", \"wuzzy fuzzy was a bear\"))\n",
    "print(\"fuzz.token_sort_ratio('fuzzy wuzzy was a bear', 'wuzzy fuzzy was a bear')\", fuzz.token_sort_ratio(\"fuzzy wuzzy was a bear\", \"wuzzy fuzzy was a bear\"))\n",
    "    #WRATIO == Set Ratio?\n",
    "print(\"fuzz.token_sort_ratio('fuzzy was a bear', 'fuzzy fuzzy was a bear')\", fuzz.token_sort_ratio(\"fuzzy was a bear\", \"fuzzy fuzzy was a bear\"))\n",
    "print(\"fuzz.token_set_ratio('fuzzy was a bear', 'fuzzy fuzzy was a bear')\", fuzz.token_set_ratio(\"fuzzy was a bear\", \"fuzzy fuzzy was a bear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base1.shape)\n",
    "base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base2.shape)\n",
    "base2.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netw4ppl",
   "language": "python",
   "name": "netw4ppl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
